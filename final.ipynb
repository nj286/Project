{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFzmYol24Fwt",
        "outputId": "fe95afc0-582a-44cc-fd24-99d74a8c0778"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkzfo_Eh4p_t"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "mMtQRHib4zZU",
        "outputId": "2b042535-21c5-44d4-d72b-52860a5aa438"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Capstone_project/cleaned_reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_reviews</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>excellent</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dog become healthy thank</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>quality service everyone happy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>went top dog raw food morning first time amazi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>very stylish site enough information make choi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     cleaned_reviews  rating\n",
              "0                                          excellent       5\n",
              "1                           dog become healthy thank       5\n",
              "2                     quality service everyone happy       5\n",
              "3  went top dog raw food morning first time amazi...       5\n",
              "4  very stylish site enough information make choi...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ue5dEsl4KPn"
      },
      "source": [
        "df= df.rename(columns={\"cleaned_reviews\": \"comment\", \"rating\": \"rating\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "e94TvYgq5bFX",
        "outputId": "236b8622-1a2c-4652-d8b6-6db8fd616155"
      },
      "source": [
        "df = df[['comment','rating']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>excellent</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dog become healthy thank</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>quality service everyone happy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>went top dog raw food morning first time amazi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>very stylish site enough information make choi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  rating\n",
              "0                                          excellent       5\n",
              "1                           dog become healthy thank       5\n",
              "2                     quality service everyone happy       5\n",
              "3  went top dog raw food morning first time amazi...       5\n",
              "4  very stylish site enough information make choi...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bli3xi_4iTWu"
      },
      "source": [
        "Mapping classes from 5 --> 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYd6mpAa5hpx"
      },
      "source": [
        "def get_index(x):\n",
        "  \n",
        "  index_1,index_2,index_3,index_4,index_5 = [], [], [], [], []\n",
        "  for ind,val in enumerate(x):\n",
        "\n",
        "    if val == 1:\n",
        "      index_1.append(ind)\n",
        "    #elif val == 2:\n",
        "     # index_2.append(ind)\n",
        "    elif val == 3:\n",
        "      index_3.append(ind)\n",
        "    #elif val == 4:\n",
        "     # index_4.append(ind)\n",
        "    elif val == 5:\n",
        "      index_5.append(ind)\n",
        "  print(len(index_1),len(index_3),len(index_5))\n",
        "\n",
        "  index = index_1[:len(index_3)] + index_3[:] + index_5[:len(index_3)]\n",
        "  print(len(index))\n",
        "  return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CGSuB146MmP",
        "outputId": "971623e1-6616-4ae2-dea3-968e72cab2d7"
      },
      "source": [
        "index = get_index(df['rating'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97645 42016 925883\n",
            "126048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1eNncZz6Pay"
      },
      "source": [
        "df_train= df.loc[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJkdXkwB9Wqf"
      },
      "source": [
        "X = df_train.comment\n",
        "y = df_train.rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z09Yt5VcifG2"
      },
      "source": [
        "Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-FSYcbL84s7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apI3AvWj9juZ",
        "outputId": "29408c00-901b-4985-9e0c-be310a0f85ff"
      },
      "source": [
        "X_train = [s.lower() for s in X_train]\n",
        "print(len(X_train))\n",
        "print(X_train[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84452\n",
            "['good experience petswag product not available promised good communication regarding late shipment appreciated would business ordered car safety harness clickit tried yet judging great review work great', 'loved website bulk option let order without personal agent setting account came freaking fast']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmWVPZW--VoV",
        "outputId": "f7a09aa4-3e38-4a3c-d72b-d29f5ba163aa"
      },
      "source": [
        "X_test = [s.lower() for s in X_test]\n",
        "print(len(X_test))\n",
        "print(X_test[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41596\n",
            "['very responsive twitter costumer service shipment delayed no response email contact soon messaged twitter emma touch solved issue immediately wish contacted twitter sooner', 'tried time touch order not arrived no response previously stated no telephone number customer service non existent']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MucISx7-kJK"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMdZyzj0ikMI"
      },
      "source": [
        "Tokenizing the data, will be fitting on training set only. This will create vocabulary on training data. \r\n",
        "\r\n",
        "Tokenization is done using character level, characters a-z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t89L2UDg-wGr"
      },
      "source": [
        "# Initialization\n",
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "# Fitting\n",
        "tk.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W78qRAr-6RY",
        "outputId": "b7672352-c759-4ab0-949d-edfe6bb4c223"
      },
      "source": [
        "# List the vocabulary\n",
        "print(tk.word_index)\n",
        "print(len(tk.word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'UNK': 1, ' ': 2, 'e': 3, 'r': 4, 'o': 5, 't': 6, 'a': 7, 'i': 8, 'n': 9, 'l': 10, 's': 11, 'd': 12, 'c': 13, 'p': 14, 'u': 15, 'm': 16, 'g': 17, 'y': 18, 'h': 19, 'v': 20, 'w': 21, 'f': 22, 'k': 23, 'b': 24, 'x': 25, 'q': 26, 'z': 27, 'j': 28}\n",
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl3G7qtGjIBt"
      },
      "source": [
        "Each sentence is converted based on tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOVw5qpa-_P6",
        "outputId": "d4dee95c-baa2-4fa7-ea93-6dd481bcebed"
      },
      "source": [
        "sequences = tk.texts_to_sequences(X_train)\n",
        "print(X_train[0])\n",
        "print(sequences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "good experience petswag product not available promised good communication regarding late shipment appreciated would business ordered car safety harness clickit tried yet judging great review work great\n",
            "[17, 5, 5, 12, 2, 3, 25, 14, 3, 4, 8, 3, 9, 13, 3, 2, 14, 3, 6, 11, 21, 7, 17, 2, 14, 4, 5, 12, 15, 13, 6, 2, 9, 5, 6, 2, 7, 20, 7, 8, 10, 7, 24, 10, 3, 2, 14, 4, 5, 16, 8, 11, 3, 12, 2, 17, 5, 5, 12, 2, 13, 5, 16, 16, 15, 9, 8, 13, 7, 6, 8, 5, 9, 2, 4, 3, 17, 7, 4, 12, 8, 9, 17, 2, 10, 7, 6, 3, 2, 11, 19, 8, 14, 16, 3, 9, 6, 2, 7, 14, 14, 4, 3, 13, 8, 7, 6, 3, 12, 2, 21, 5, 15, 10, 12, 2, 24, 15, 11, 8, 9, 3, 11, 11, 2, 5, 4, 12, 3, 4, 3, 12, 2, 13, 7, 4, 2, 11, 7, 22, 3, 6, 18, 2, 19, 7, 4, 9, 3, 11, 11, 2, 13, 10, 8, 13, 23, 8, 6, 2, 6, 4, 8, 3, 12, 2, 18, 3, 6, 2, 28, 15, 12, 17, 8, 9, 17, 2, 17, 4, 3, 7, 6, 2, 4, 3, 20, 8, 3, 21, 2, 21, 5, 4, 23, 2, 17, 4, 3, 7, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_HJww7I_MAL",
        "outputId": "626b5419-ec12-4eea-8863-f2b3a9636314"
      },
      "source": [
        "sequences_test = tk.texts_to_sequences(X_test)\n",
        "print(X_test[0])\n",
        "print(sequences_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "very responsive twitter costumer service shipment delayed no response email contact soon messaged twitter emma touch solved issue immediately wish contacted twitter sooner\n",
            "[20, 3, 4, 18, 2, 4, 3, 11, 14, 5, 9, 11, 8, 20, 3, 2, 6, 21, 8, 6, 6, 3, 4, 2, 13, 5, 11, 6, 15, 16, 3, 4, 2, 11, 3, 4, 20, 8, 13, 3, 2, 11, 19, 8, 14, 16, 3, 9, 6, 2, 12, 3, 10, 7, 18, 3, 12, 2, 9, 5, 2, 4, 3, 11, 14, 5, 9, 11, 3, 2, 3, 16, 7, 8, 10, 2, 13, 5, 9, 6, 7, 13, 6, 2, 11, 5, 5, 9, 2, 16, 3, 11, 11, 7, 17, 3, 12, 2, 6, 21, 8, 6, 6, 3, 4, 2, 3, 16, 16, 7, 2, 6, 5, 15, 13, 19, 2, 11, 5, 10, 20, 3, 12, 2, 8, 11, 11, 15, 3, 2, 8, 16, 16, 3, 12, 8, 7, 6, 3, 10, 18, 2, 21, 8, 11, 19, 2, 13, 5, 9, 6, 7, 13, 6, 3, 12, 2, 6, 21, 8, 6, 6, 3, 4, 2, 11, 5, 5, 9, 3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfHPMqk4jP74"
      },
      "source": [
        "Setting the length to 1014 using post padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MczYaAq_Ue2"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=1014, padding='post')\n",
        "data_test = pad_sequences(sequences_test, maxlen=1014, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIvEnffkjhgu"
      },
      "source": [
        "Convert into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK3Ww7w8_fSu",
        "outputId": "ce6c02d4-a31d-48f8-c92e-b0f507c3caa4"
      },
      "source": [
        "data = np.array(data)\n",
        "data_test = np.array(data_test)\n",
        "print(data.shape) # All sentence length are 1014\n",
        "print(data_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(84452, 1014)\n",
            "(41596, 1014)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MXuS5QB_zZP",
        "outputId": "e9a97f6d-f290-4c90-f34c-4853bb7462b0"
      },
      "source": [
        "class_list = y_train\n",
        "class_list_test = y_test\n",
        "print(set(class_list),set(class_list_test))\n",
        "print(len(class_list)) # how many length\n",
        "print(class_list[:10]) # print top 10 samples classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 3, 5} {1, 3, 5}\n",
            "84452\n",
            "32526      5\n",
            "26405      5\n",
            "1049832    3\n",
            "36817      1\n",
            "488989     1\n",
            "10943      5\n",
            "477671     1\n",
            "241515     1\n",
            "49206      5\n",
            "28833      1\n",
            "Name: rating, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkdoPwMbjn0r"
      },
      "source": [
        "Reducing classes to 0,1,2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMcWsa_EBdfb"
      },
      "source": [
        "def mapp(l):\n",
        "  m_list=[]\n",
        "  for i,val in enumerate(l):\n",
        "    if val == 1:\n",
        "      m_list.append(0)\n",
        "    elif val == 3:\n",
        "      m_list.append(1)\n",
        "    else:\n",
        "      m_list.append(2)\n",
        "  return m_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXzl-tGyEkYA",
        "outputId": "dbebf8ff-19fb-4228-843d-4a05727dfaa3"
      },
      "source": [
        "class_list = mapp(class_list) # change index from [1, 3, 5] to [0, 1, 2] in order to use to_categorical()\n",
        "class_list_test = mapp(class_list_test)\n",
        "print(set(class_list))\n",
        "print(set(class_list_test)) \n",
        "print(class_list[:5]) # print top 5 samples classes to comfirm the changes\n",
        "print(class_list_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2}\n",
            "{0, 1, 2}\n",
            "[2, 2, 1, 0, 0]\n",
            "[1, 0, 1, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGPmsgBDjsMZ"
      },
      "source": [
        "Creating one-hot representation of target variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbmd_jG4E7qZ",
        "outputId": "1379a994-6e87-481b-8867-70a6a7bd5442"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "classes_train = to_categorical(class_list)\n",
        "classes_test = to_categorical(class_list_test)\n",
        "print(classes_train[:10])\n",
        "class_list=None\n",
        "class_list_test=None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0RQMY6KE9MN",
        "outputId": "7406f718-55ef-4921-973e-262dfed6d87d"
      },
      "source": [
        "vocab_size = len(tk.word_index)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZzQ48Ftj31P"
      },
      "source": [
        "Creating Embedded weights of 71*70 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN8TjMokK1H5"
      },
      "source": [
        "embedding_weights = [] #(71, 70)\n",
        "embedding_weights.append(np.zeros(vocab_size)) # first row is pad\n",
        "\n",
        "for char, i in tk.word_index.items(): # from index 1 to 70\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i-1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "embedding_weights = np.array(embedding_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SctMF_yHL1ix",
        "outputId": "3b663b94-82bf-4489-8876-58919298aab9"
      },
      "source": [
        "print(embedding_weights.shape) # first row all 0 for PAD, 69 char, last row for UNK\n",
        "embedding_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3hK61V0kBzP"
      },
      "source": [
        "We are using 1D CNN with emdedded layer, maxpooling layer and dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pj6Pg2gL4Ta"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0dEUk2kO-9"
      },
      "source": [
        "Setting the filter size, input/output dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXv7AsYVL6_Q"
      },
      "source": [
        "# parameter \n",
        "input_size = 1014\n",
        "# vocab_size = 69\n",
        "embedding_size = vocab_size\n",
        "conv_layers = [[256, 7, 3], \n",
        "               [256, 7, 3], \n",
        "               [256, 3, -1], \n",
        "               [256, 3, -1], \n",
        "               [256, 3, -1], \n",
        "               [256, 3, 3]]\n",
        "\n",
        "fully_connected_layers = [1024, 1024]\n",
        "num_of_classes = 3\n",
        "dropout_p = 0.5\n",
        "optimizer = 'adam'\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI3_XxmTL9zG"
      },
      "source": [
        "# Embedding layer Initialization\n",
        "embedding_layer = Embedding(vocab_size+1, \n",
        "                            embedding_size,\n",
        "                            input_length=input_size,\n",
        "                            weights=[embedding_weights])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtRipLNaMAUc",
        "outputId": "990c90b6-d5c8-464a-b086-f2084597df33"
      },
      "source": [
        "\n",
        "# Input\n",
        "inputs = Input(shape=(input_size,), name='input', dtype='int64')  # shape=(?, 1014)\n",
        "# Embedding \n",
        "x = embedding_layer(inputs)\n",
        "# Conv \n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x) \n",
        "    x = Activation('relu')(x)\n",
        "    if pooling_size != -1:\n",
        "        x = MaxPooling1D(pool_size=pooling_size)(x) # Final shape=(None, 34, 256)\n",
        "x = Flatten()(x) # (None, 8704)\n",
        "# Fully connected layers \n",
        "for dense_size in fully_connected_layers:\n",
        "    x = Dense(dense_size, activation='relu')(x) # dense_size == 1024\n",
        "    x = Dropout(dropout_p)(x)\n",
        "# Output Layer\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "# Build model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) # Adam, categorical_crossentropy\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1014)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1014, 28)          812       \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 1008, 256)         50432     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1008, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 336, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 330, 256)          459008    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 330, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 110, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 108, 256)          196864    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 108, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 106, 256)          196864    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 106, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 104, 256)          196864    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 104, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 102, 256)          196864    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 102, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 34, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8704)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              8913920   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 11,264,303\n",
            "Trainable params: 11,264,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxnoG-cMDBC",
        "outputId": "bda2680a-358c-4eaa-9734-fe1f6532e208"
      },
      "source": [
        "# Training\n",
        "model.fit(data, classes_train,\n",
        "          validation_data=(data_test, classes_test),\n",
        "          batch_size=128,\n",
        "          epochs=6,\n",
        "          verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "660/660 - 59s - loss: 0.9005 - accuracy: 0.5586 - val_loss: 0.7812 - val_accuracy: 0.6426\n",
            "Epoch 2/6\n",
            "660/660 - 61s - loss: 0.7403 - accuracy: 0.6754 - val_loss: 0.7105 - val_accuracy: 0.6864\n",
            "Epoch 3/6\n",
            "660/660 - 63s - loss: 0.6883 - accuracy: 0.7049 - val_loss: 0.6985 - val_accuracy: 0.6948\n",
            "Epoch 4/6\n",
            "660/660 - 62s - loss: 0.6468 - accuracy: 0.7262 - val_loss: 0.7175 - val_accuracy: 0.6853\n",
            "Epoch 5/6\n",
            "660/660 - 63s - loss: 0.6088 - accuracy: 0.7463 - val_loss: 0.7889 - val_accuracy: 0.6706\n",
            "Epoch 6/6\n",
            "660/660 - 63s - loss: 0.5666 - accuracy: 0.7667 - val_loss: 0.7469 - val_accuracy: 0.6847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efc60035cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA5I3TPykjKM"
      },
      "source": [
        "# We get an accuracy of 68%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPpa7uKHkw24"
      },
      "source": [
        "# Trying to see how logistic regression works on the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ef9KjDXMF4m"
      },
      "source": [
        "### After split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boda1GhEr66Z"
      },
      "source": [
        "def mapp(l):\n",
        "  m_list=[]\n",
        "  for i,val in enumerate(l):\n",
        "    if val == 1 :\n",
        "      m_list.append(0)\n",
        "    elif val == 3:\n",
        "      m_list.append(1)\n",
        "    else:\n",
        "      m_list.append(2)\n",
        "  return m_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIUHW_ns9jI"
      },
      "source": [
        "y_train = mapp(y_train)\n",
        "y_test = mapp(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nV0PZkWtLoj",
        "outputId": "9ec3f599-8631-41b2-f421-54bb73802be1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tvec1 = TfidfVectorizer(max_features=10000,ngram_range=(1, 3))\n",
        "tvec1.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
              "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkQTrQpTtWD5"
      },
      "source": [
        "X_train = tvec1.transform(X_train)\n",
        "X_test = tvec1.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvahgurJtm-Z"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgaYWx9RuiiE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix # Confusion matrix\n",
        "from sklearn.metrics import classification_report # precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOP1miWstwEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYmwYn5xt9Fz",
        "outputId": "fadf38d6-bfe1-4a80-e911-b8d283dae025"
      },
      "source": [
        "clf_lr = LogisticRegression(max_iter=300)\n",
        "print(clf_lr)\n",
        "clf_lr.fit(X_train, y_train)\n",
        "pred_lr = clf_lr.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, pred_lr))\n",
        "\n",
        "# Precision, Recall, F1-score \n",
        "print(classification_report(y_test, pred_lr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=300,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "[[ 9436  2840  1639]\n",
            " [ 2470  9243  2172]\n",
            " [  603  1458 11735]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.68      0.71     13915\n",
            "           1       0.68      0.67      0.67     13885\n",
            "           2       0.75      0.85      0.80     13796\n",
            "\n",
            "    accuracy                           0.73     41596\n",
            "   macro avg       0.73      0.73      0.73     41596\n",
            "weighted avg       0.73      0.73      0.73     41596\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1KTacIhk4dN"
      },
      "source": [
        "# Logistic Regression gives 73% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx7w_RYBt-3v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}